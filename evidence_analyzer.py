#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯æ®åˆ†æç³»ç»Ÿ
ç”¨äºåˆ†ææ³•å¾‹æ¡ˆä»¶è¯æ®å¹¶ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š
"""

import json
import os
import re
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime
import requests
from dataclasses import dataclass
from enum import Enum
from openai import OpenAI
import time
import logging

class EvidenceType(Enum):
    """è¯æ®ç±»å‹æšä¸¾"""
    CONTRACT = "contract"  # åˆåŒç±»æ–‡ä»¶
    PAYMENT = "payment"   # è–ªèµ„è®°å½•
    ATTENDANCE = "attendance"  # è€ƒå‹¤æ•°æ®
    MEDICAL = "medical"   # å·¥ä¼¤ææ–™
    MEDIA = "media"       # éŸ³è§†é¢‘
    CHAT = "chat"         # èŠå¤©è®°å½•

@dataclass
class APIConfig:
    """APIé…ç½®æ•°æ®ç»“æ„"""
    url: str
    method: str = "POST"
    file_param: str = "file"
    additional_params: Dict[str, str] = None
    
    def __post_init__(self):
        if self.additional_params is None:
            self.additional_params = {}

@dataclass
class EvidenceItem:
    """è¯æ®é¡¹æ•°æ®ç»“æ„"""
    evidence_type: EvidenceType
    description: str
    keywords: List[str]
    required: bool = True
    file_path: Optional[str] = None
    analysis_result: Optional[Dict] = None

class EvidenceAnalyzer:
    """è¯æ®åˆ†æå™¨ä¸»ç±»"""
    
    def __init__(self, openai_api_key: Optional[str] = None, api_config_file: str = "æ¥å£è¯´æ˜.txt"):
        """
        åˆå§‹åŒ–è¯æ®åˆ†æå™¨
        
        Args:
            openai_api_key: OpenAI APIå¯†é’¥
            api_config_file: APIé…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.openai_base_url = "https://ark.cn-beijing.volces.com/api/v3"
        self.openai_client = OpenAI(
            api_key=openai_api_key or "1b4bef68-37d5-4196-ba8b-17c9054ae9c5",
            base_url=self.openai_base_url
        )
        self.evidence_patterns = self._init_evidence_patterns()
        self.api_config_file = api_config_file
        
        # è®¾ç½®æ—¥å¿—ï¼ˆå¿…é¡»åœ¨_load_api_configsä¹‹å‰ï¼‰
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        self.api_configs = self._load_api_configs()
        
    def _init_evidence_patterns(self) -> Dict[EvidenceType, Dict[str, List[str]]]:
        """åˆå§‹åŒ–è¯æ®è¯†åˆ«æ¨¡å¼"""
        return {
            EvidenceType.CONTRACT: {
                "keywords": ["åŠ³åŠ¨åˆåŒ", "è¾é€€é€šçŸ¥ä¹¦", "ç«ä¸šåè®®", "å®ä¹ åˆåŒ", "ç«ä¸šåè®®", "é€šçŸ¥ä¹¦"],
                "descriptions": ["ä¹¦é¢åŠ³åŠ¨åˆåŒ", "è¾é€€é€šçŸ¥", "è§£é™¤åˆåŒé€šçŸ¥"]
            },
            EvidenceType.PAYMENT: {
                "keywords": ["é“¶è¡Œæµæ°´", "å·¥èµ„å•", "å·¥èµ„æ¡"],
                "descriptions": ["å·¥èµ„é“¶è¡Œæµæ°´", "è–ªèµ„å‘æ”¾è®°å½•", "æ”¶å…¥è¯æ˜"]
            },
            EvidenceType.ATTENDANCE: {
                "keywords": ["è€ƒå‹¤å•", "æ‰“å¡è®°å½•"],
                "descriptions": ["è€ƒå‹¤æ‰“å¡è®°å½•", "è¯·å‡å®¡æ‰¹è®°å½•", "å·¥ä½œæ—¶é—´è¯æ˜"]
            },
            EvidenceType.MEDICAL: {
                "keywords": ["å·¥ä¼¤", "è¯Šæ–­ä¹¦", "ç—…å†", "åŒ»ç–—"],
                "descriptions": ["å·¥ä¼¤è¯Šæ–­è¯æ˜", "åŒ»ç–—è®°å½•", "ä¼¤æƒ…é‰´å®š"]
            },
            EvidenceType.MEDIA: {
                "keywords": ["å½•éŸ³", "å½•åƒ", "é€šè¯è®°å½•"],
                "descriptions": ["å½•éŸ³è¯æ®", "è§†é¢‘èµ„æ–™", "é€šè¯è®°å½•"]
            },
            EvidenceType.CHAT: {
                "keywords": ["å¾®ä¿¡", "é’‰é’‰", "é£ä¹¦", "èŠå¤©è®°å½•"],
                "descriptions": ["èŠå¤©è®°å½•æˆªå›¾", "å·¥ä½œç¾¤å¯¹è¯", "æ²Ÿé€šè®°å½•"]
            }
        }
    
    def analyze_case_evidence(self, conversation_file_path: str) -> Dict[str, Any]:
        """
        åˆ†ææ¡ˆä»¶è¯æ®çš„ä¸»å‡½æ•°
        
        Args:
            conversation_file_path: å¯¹è¯å†å²æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«æ‰€æœ‰è¯æ®åˆ†æç»“æœçš„ç»¼åˆæŠ¥å‘Š
        """
        print("ğŸ” å¼€å§‹åˆ†ææ¡ˆä»¶è¯æ®...")
        
        # 1. è§£æå¯¹è¯å†å²
        conversation_data = self._load_conversation_history(conversation_file_path)
        if not conversation_data:
            return {"error": "æ— æ³•åŠ è½½å¯¹è¯å†å²æ–‡ä»¶"}
        
        # 2. è¯†åˆ«è¯æ®éœ€æ±‚
        evidence_items = self._identify_evidence_from_conversation(conversation_data)
        print(f"ğŸ“‹ è¯†åˆ«åˆ° {len(evidence_items)} ç±»è¯æ®éœ€æ±‚")
        print(evidence_items)
        
        # 3. å¼•å¯¼ç”¨æˆ·ä¸Šä¼ è¯æ®
        uploaded_evidence = self._guide_evidence_upload(evidence_items)
        
        # 4. åˆ†ææ¯ä¸ªè¯æ®
        analysis_results = {}
        for evidence_type, evidence_list in uploaded_evidence.items():
            for evidence in evidence_list:
                if evidence.file_path:
                    print(f"ğŸ”¬ æ­£åœ¨åˆ†æ {evidence.description} ({evidence_type.value} ç±»è¯æ®)...")
                    analysis_result = self._analyze_single_evidence(evidence)
                    evidence.analysis_result = analysis_result
                    
                    # ä¸ºæ¯ä¸ªå…·ä½“çš„è¯æ®åˆ›å»ºå”¯ä¸€çš„åˆ†æé”®
                    analysis_key = f"{evidence_type.value}_{evidence.description}_analysis"
                    if analysis_key not in analysis_results:
                        analysis_results[analysis_key] = []
                    analysis_results[analysis_key].append(analysis_result)
                    print(f"âœ… {evidence.description} åˆ†æå®Œæˆ")
        
        # 5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        comprehensive_report = self._generate_comprehensive_report(
            evidence_items, analysis_results, conversation_data
        )
        
        # 6. ä¿å­˜æŠ¥å‘Š
        report_file = self._save_report(comprehensive_report)
        print(f"ğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
        
        return comprehensive_report
    
    def _load_conversation_history(self, file_path: str) -> Optional[List[Dict]]:
        """åŠ è½½å¯¹è¯å†å²æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list) and len(data) > 0:
                    return data[0].get('conversations', [])
                return data
        except Exception as e:
            print(f"âŒ åŠ è½½å¯¹è¯å†å²å¤±è´¥: {e}")
            return None
    
    def _identify_evidence_from_conversation(self, conversations: List[Dict]) -> Dict[EvidenceType, List[EvidenceItem]]:
        """ä»å¯¹è¯ä¸­è¯†åˆ«è¯æ®éœ€æ±‚"""
        evidence_items = {evidence_type: [] for evidence_type in EvidenceType}
        
        # åˆå¹¶æ‰€æœ‰å¯¹è¯å†…å®¹
        full_text = ""
        for conv in conversations:
            if conv.get('value'):
                full_text += conv['value'] + " "
        
        # ä½¿ç”¨å…³é”®è¯åŒ¹é…è¯†åˆ«è¯æ®ç±»å‹ï¼Œä¸ºæ¯ä¸ªå…³é”®è¯åˆ›å»ºç‹¬ç«‹çš„è¯æ®é¡¹
        for evidence_type, patterns in self.evidence_patterns.items():
            found_keywords = []
            for keyword in patterns['keywords']:
                if keyword in full_text:
                    found_keywords.append(keyword)
            
            # ä¸ºæ¯ä¸ªæ‰¾åˆ°çš„å…³é”®è¯åˆ›å»ºç‹¬ç«‹çš„è¯æ®é¡¹
            for keyword in found_keywords:
                evidence_item = EvidenceItem(
                    evidence_type=evidence_type,
                    description=f"{keyword}",  # ä½¿ç”¨å…·ä½“çš„å…³é”®è¯ä½œä¸ºæè¿°
                    keywords=[keyword],  # æ¯ä¸ªè¯æ®é¡¹åªåŒ…å«ä¸€ä¸ªå…³é”®è¯
                    required=True
                )
                evidence_items[evidence_type].append(evidence_item)
        
        return evidence_items
    
    def _guide_evidence_upload(self, evidence_items: Dict[EvidenceType, List[EvidenceItem]]) -> Dict[EvidenceType, List[EvidenceItem]]:
        """å¼•å¯¼ç”¨æˆ·ä¸Šä¼ è¯æ®æ–‡ä»¶"""
        print("\nğŸ“¤ è¯·æŒ‰ç…§æç¤ºä¸Šä¼ ç›¸å…³è¯æ®æ–‡ä»¶ï¼š")
        print("=" * 50)
        print("ğŸ’¡ æç¤ºï¼šç°åœ¨å¯ä»¥ä¸ºæ¯ç§å…·ä½“çš„è¯æ®ç±»å‹å•ç‹¬ä¸Šä¼ æ–‡ä»¶")
        print("   ä¾‹å¦‚ï¼šåŠ³åŠ¨åˆåŒã€è¾é€€é€šçŸ¥ä¹¦å¯ä»¥åˆ†åˆ«ä¸Šä¼ ä¸åŒçš„æ–‡ä»¶")
        print()
        
        uploaded_evidence = {}
        
        for evidence_type, items in evidence_items.items():
            if not items:
                continue
                
            uploaded_evidence[evidence_type] = []
            
            print(f"\nğŸ“ {self._get_evidence_type_name(evidence_type)} ç±»è¯æ®:")
            
            for i, item in enumerate(items, 1):
                print(f"  {i}. ğŸ“„ {item.description}")
                print(f"     ğŸ“ è¯´æ˜: è¯·ä¸Šä¼ ä¸'{item.description}'ç›¸å…³çš„æ–‡ä»¶")
                
                # æ¨¡æ‹Ÿç”¨æˆ·ä¸Šä¼ ï¼ˆå®é™…åº”ç”¨ä¸­è¿™é‡Œåº”è¯¥æ˜¯æ–‡ä»¶ä¸Šä¼ ç•Œé¢ï¼‰
                file_path = input(f"     ğŸ“‚ è¯·è¾“å…¥æ–‡ä»¶è·¯å¾„ (å›è½¦è·³è¿‡): ").strip()
                
                if file_path and os.path.exists(file_path):
                    item.file_path = file_path
                    uploaded_evidence[evidence_type].append(item)
                    print(f"     âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file_path}")
                    print(f"     ğŸ“‹ å°†åˆ†æ: {item.description}")
                elif file_path:
                    print(f"     âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                    print(f"     ğŸ’¡ è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
                else:
                    print(f"     â­ï¸ è·³è¿‡ {item.description}")
                print()  # æ·»åŠ ç©ºè¡Œåˆ†éš”
        
        return uploaded_evidence
    
    def _analyze_single_evidence(self, evidence: EvidenceItem) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªè¯æ®æ–‡ä»¶"""
        self.logger.info(f"å¼€å§‹åˆ†æ {evidence.evidence_type.value} ç±»å‹çš„è¯æ®æ–‡ä»¶: {evidence.file_path}")
        
        # è·å–æ¨¡æ‹Ÿåˆ†æç»“æœä½œä¸ºå¤‡ç”¨
        mock_analysis = self._get_mock_analysis_result(evidence)
        
        # å°è¯•è°ƒç”¨å¯¹åº”çš„API
        if self.api_configs and evidence.evidence_type in self.api_configs:
            api_result = self._call_evidence_api(evidence)
            
            if api_result:
                self.logger.info(f"ä½¿ç”¨APIåˆ†æç»“æœ: {evidence.evidence_type.value}")
                return api_result
            else:
                self.logger.warning(f"APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿåˆ†æç»“æœ: {evidence.evidence_type.value}")
                return mock_analysis
        else:
            self.logger.info(f"æœªé…ç½®APIæˆ–APIä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿåˆ†æç»“æœ: {evidence.evidence_type.value}")
            return mock_analysis
    
    def _get_mock_analysis_result(self, evidence: EvidenceItem) -> Dict[str, Any]:
        """è·å–æ¨¡æ‹Ÿçš„åˆ†æç»“æœ"""
        base_result = {
            "æ–‡ä»¶ç±»å‹": self._get_evidence_type_name(evidence.evidence_type),
            "æ–‡ä»¶æœ‰æ•ˆæ€§è¯´æ˜": "æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼Œå†…å®¹æ¸…æ™°å¯è¯»ã€‚",
            "ä¸æ¡ˆä»¶å…³è”æ€§åˆ†æ": "ä¸æœ¬æ¡ˆä»¶å…·æœ‰ç›´æ¥å…³è”æ€§ã€‚",
            "æ˜¯å¦å¯ä»¥ä½œä¸ºæ ¸å¿ƒè¯æ®": "æ˜¯"
        }
        
        # æ ¹æ®è¯æ®ç±»å‹æ·»åŠ ç‰¹å®šå­—æ®µ
        if evidence.evidence_type == EvidenceType.CONTRACT:
            base_result.update({
                "ä¸»ä½“å…¬å¸åç§°": "XXç§‘æŠ€æœ‰é™å…¬å¸",
                "åˆåŒèµ·å§‹æ—¥æœŸ": "2022å¹´09æœˆ01æ—¥",
                "åˆåŒæœ‰æ•ˆæœŸ": "3å¹´",
                "çº¦å®šè–ªèµ„": "12000å…ƒ/æœˆ",
                "å…³é”®ä¿¡æ¯æ‘˜è¦": "åˆåŒçº¦å®šå·¥ä½œå¹´é™3å¹´ï¼Œæœˆè–ª12000å…ƒï¼ŒåŒ…å«è¯•ç”¨æœŸæ¡æ¬¾ã€‚"
            })
        elif evidence.evidence_type == EvidenceType.PAYMENT:
            base_result.update({
                "å·¥èµ„å‘æ”¾æ–¹å¼": "é“¶è¡Œè½¬è´¦",
                "å‘æ”¾å‘¨æœŸ": "æ¯æœˆ15æ—¥",
                "å¹³å‡æœˆè–ª": "12000å…ƒ",
                "å…³é”®ä¿¡æ¯æ‘˜è¦": "é“¶è¡Œæµæ°´æ˜¾ç¤ºæ¯æœˆ15æ—¥å®šæœŸæ”¶åˆ°å·¥èµ„è½¬è´¦ï¼Œé‡‘é¢ç¨³å®šã€‚"
            })
        elif evidence.evidence_type == EvidenceType.ATTENDANCE:
            base_result.update({
                "è€ƒå‹¤æ–¹å¼": "æ‰“å¡ç³»ç»Ÿ",
                "å·¥ä½œæ—¶é—´": "9:00-18:00",
                "å…³é”®ä¿¡æ¯æ‘˜è¦": "è€ƒå‹¤è®°å½•æ˜¾ç¤ºæ­£å¸¸ä¸Šä¸‹ç­æ‰“å¡ï¼Œå­˜åœ¨ç®¡ç†å…³ç³»ã€‚"
            })
        elif evidence.evidence_type == EvidenceType.MEDIA:
            base_result.update({
                "å…³é”®å†…å®¹æ‘˜è¦ï¼ˆæ–‡å­—ç¨¿ï¼‰": "å½•éŸ³ä¸­åŒ…å«å…³é”®å¯¹è¯å†…å®¹ï¼Œè¯æ˜ç›¸å…³äº‹å®ã€‚",
                "æ˜¯å¦å¯ä»¥ä½œä¸ºæ ¸å¿ƒè¯æ®": "å¦ï¼Œå»ºè®®ä½œä¸ºè¾…åŠ©è¯æ®"
            })
        elif evidence.evidence_type == EvidenceType.CHAT:
            base_result.update({
                "èŠå¤©å¹³å°": "å¾®ä¿¡",
                "å…³é”®ä¿¡æ¯æ‘˜è¦": "èŠå¤©è®°å½•æ˜¾ç¤ºå·¥ä½œå®‰æ’å’Œæ²Ÿé€šå†…å®¹ã€‚"
            })
        
        return base_result
    
    def _generate_comprehensive_report(self, evidence_items: Dict, analysis_results: Dict, conversation_data: List) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...")
        
        # ä½¿ç”¨LLMç”Ÿæˆæ€»ç»“
        summary = self._generate_llm_summary(analysis_results, conversation_data)
        
        # åˆ†ç±»è¯æ®
        core_evidence = []
        supporting_evidence = []
        
        for analysis_type, results in analysis_results.items():
            for result in results:
                if result.get("æ˜¯å¦å¯ä»¥ä½œä¸ºæ ¸å¿ƒè¯æ®") == "æ˜¯":
                    core_evidence.append({
                        "ç±»å‹": result.get("æ–‡ä»¶ç±»å‹", "æœªçŸ¥"),
                        "æ‘˜è¦": result.get("å…³é”®ä¿¡æ¯æ‘˜è¦", "æ— æ‘˜è¦")
                    })
                else:
                    supporting_evidence.append({
                        "ç±»å‹": result.get("æ–‡ä»¶ç±»å‹", "æœªçŸ¥"),
                        "æ‘˜è¦": result.get("å…³é”®ä¿¡æ¯æ‘˜è¦", "æ— æ‘˜è¦")
                    })
        
        comprehensive_report = {
            "æŠ¥å‘Šç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "æ¡ˆä»¶æ¦‚è¿°": self._extract_case_summary(conversation_data),
            "è¯æ®åˆ†æç»“æœ": analysis_results,
            "æ ¸å¿ƒè¯æ®åˆ—è¡¨": core_evidence,
            "è¾…åŠ©è¯æ®åˆ—è¡¨": supporting_evidence,
            "LLMç»¼åˆåˆ†æ": summary,
            "è¯æ®å®Œæ•´æ€§è¯„ä¼°": self._assess_evidence_completeness(evidence_items, analysis_results),
            "å»ºè®®å’Œé£é™©æç¤º": self._generate_recommendations(analysis_results)
        }
        
        return comprehensive_report
    
    def _generate_llm_summary(self, analysis_results: Dict, conversation_data: List) -> str:
        """ä½¿ç”¨LLMç”Ÿæˆåˆ†ææ€»ç»“"""
        try:
            # æ„å»ºæç¤ºè¯
            prompt = f"""
            è¯·åŸºäºä»¥ä¸‹è¯æ®åˆ†æç»“æœå’Œæ¡ˆä»¶å¯¹è¯ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„æ³•å¾‹è¯æ®åˆ†ææ€»ç»“ï¼š
            
            è¯æ®åˆ†æç»“æœï¼š
            {json.dumps(analysis_results, ensure_ascii=False, indent=2)}
            
            è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼š
            1. è¯æ®çš„å®Œæ•´æ€§å’Œæœ‰æ•ˆæ€§
            2. å„ç±»è¯æ®ä¹‹é—´çš„å…³è”æ€§
            3. å¯¹æ¡ˆä»¶èƒœè¯‰çš„æ”¯æŒç¨‹åº¦
            4. å¯èƒ½å­˜åœ¨çš„è¯æ®ç¼ºé™·æˆ–é£é™©
            5. è¡¥å¼ºè¯æ®çš„å»ºè®®
            
            è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€æ’°å†™ï¼Œå­—æ•°æ§åˆ¶åœ¨500å­—ä»¥å†…ã€‚
            """
            
            response = self.openai_client.chat.completions.create(
                model="doubao-seed-1-6-250615",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŠ³åŠ¨æ³•å¾‹å¸ˆï¼Œæ“…é•¿è¯æ®åˆ†æå’Œæ¡ˆä»¶è¯„ä¼°ã€‚"},
                    {"role": "user", "content": prompt}
                ]
            )
            
            return response.choices[0].message.content
        except Exception as e:
            print(f"LLMåˆ†æå¤±è´¥: {e}")
            return "åŸºäºç°æœ‰è¯æ®ï¼Œæ¡ˆä»¶å…·æœ‰ä¸€å®šçš„èƒœè¯‰å¯èƒ½æ€§ã€‚å»ºè®®è¿›ä¸€æ­¥å®Œå–„è¯æ®é“¾ï¼Œç‰¹åˆ«æ˜¯å…³é”®è¯æ®çš„è¡¥å¼ºã€‚"
    
    def _extract_case_summary(self, conversation_data: List) -> str:
        """ä»å¯¹è¯ä¸­æå–æ¡ˆä»¶æ¦‚è¿°"""
        # ç®€å•æå–å‰å‡ è½®å¯¹è¯ä½œä¸ºæ¡ˆä»¶æ¦‚è¿°
        summary_parts = []
        for i, conv in enumerate(conversation_data[:6]):  # å–å‰6è½®å¯¹è¯
            if conv.get('from') == 'human' and conv.get('value'):
                summary_parts.append(conv['value'][:100])  # æ¯æ¡é™åˆ¶100å­—ç¬¦
        
        return " ".join(summary_parts)[:300] + "..." if summary_parts else "æ— æ³•æå–æ¡ˆä»¶æ¦‚è¿°"
    
    def _assess_evidence_completeness(self, evidence_items: Dict, analysis_results: Dict) -> Dict[str, Any]:
        """è¯„ä¼°è¯æ®å®Œæ•´æ€§"""
        total_types = len([t for t, items in evidence_items.items() if items])
        analyzed_types = len(analysis_results)
        
        completeness_score = (analyzed_types / total_types * 100) if total_types > 0 else 0
        
        return {
            "å®Œæ•´æ€§å¾—åˆ†": f"{completeness_score:.1f}%",
            "å·²æ”¶é›†è¯æ®ç±»å‹": analyzed_types,
            "è¯†åˆ«è¯æ®ç±»å‹æ€»æ•°": total_types,
            "ç¼ºå¤±è¯æ®ç±»å‹": [t.value for t, items in evidence_items.items() if items and f"{t.value}_analysis" not in analysis_results]
        }
    
    def _generate_recommendations(self, analysis_results: Dict) -> List[str]:
        """ç”Ÿæˆå»ºè®®å’Œé£é™©æç¤º"""
        recommendations = []
        
        # åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®
        if "contract_analysis" in analysis_results:
            recommendations.append("âœ… åŠ³åŠ¨åˆåŒè¯æ®å……åˆ†ï¼Œæœ‰åˆ©äºè¯æ˜åŠ³åŠ¨å…³ç³»ã€‚")
        else:
            recommendations.append("âš ï¸ å»ºè®®è¡¥å……åŠ³åŠ¨åˆåŒç›¸å…³è¯æ®ã€‚")
        
        if "payment_analysis" in analysis_results:
            recommendations.append("âœ… å·¥èµ„æµæ°´è¯æ®æœ‰åŠ©äºç¡®å®šç»æµè¡¥å¿æ ‡å‡†ã€‚")
        else:
            recommendations.append("âš ï¸ å»ºè®®æä¾›å·¥èµ„å‘æ”¾è®°å½•ä»¥æ”¯æŒç»æµè¡¥å¿è¯·æ±‚ã€‚")
        
        if "media_analysis" in analysis_results:
            recommendations.append("âš ï¸ éŸ³è§†é¢‘è¯æ®éœ€æ³¨æ„å–è¯åˆæ³•æ€§ï¼Œå»ºè®®ä½œä¸ºè¾…åŠ©è¯æ®ä½¿ç”¨ã€‚")
        
        recommendations.append("ğŸ’¡ å»ºè®®å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆè¿›è¡Œè¯¦ç»†çš„æ¡ˆä»¶è¯„ä¼°ã€‚")
        
        return recommendations
    
    def _get_evidence_type_name(self, evidence_type: EvidenceType) -> str:
        """è·å–è¯æ®ç±»å‹ä¸­æ–‡åç§°"""
        type_names = {
            EvidenceType.CONTRACT: "åˆåŒç±»æ–‡ä»¶",
            EvidenceType.PAYMENT: "è–ªèµ„è®°å½•",
            EvidenceType.ATTENDANCE: "è€ƒå‹¤æ•°æ®",
            EvidenceType.MEDICAL: "åŒ»ç–—ææ–™",
            EvidenceType.MEDIA: "éŸ³è§†é¢‘è¯æ®",
            EvidenceType.CHAT: "èŠå¤©è®°å½•"
        }
        return type_names.get(evidence_type, "æœªçŸ¥ç±»å‹")
    
    def _load_api_configs(self) -> Dict[EvidenceType, APIConfig]:
        """ä»é…ç½®æ–‡ä»¶åŠ è½½APIé…ç½®ä¿¡æ¯"""
        api_configs = {}
        
        try:
            # æ ¹æ®æ¥å£è¯´æ˜.txtçš„å†…å®¹åˆ›å»ºAPIé…ç½®æ˜ å°„
            api_configs = {
                EvidenceType.CONTRACT: APIConfig(
                    url="http://localhost:8001/analyze_contract",
                    file_param="file"
                ),
                EvidenceType.PAYMENT: APIConfig(
                    url="http://localhost:8002/analyze-payslip",
                    file_param="file"
                ),
                EvidenceType.ATTENDANCE: APIConfig(
                    url="http://localhost:8003/analyze_attendance",
                    file_param="attendance_file"
                ),
                EvidenceType.MEDICAL: APIConfig(
                    url="http://localhost:8004/analyze_injury_assessment",
                    file_param="attendance_file"  # æ³¨æ„ï¼šæ¥å£æ–‡æ¡£ä¸­ä½¿ç”¨çš„æ˜¯attendance_fileå‚æ•°å
                ),
                EvidenceType.MEDIA: APIConfig(
                    url="http://localhost:8005/analyze_recording",
                    file_param="Record_file"
                ),
                EvidenceType.CHAT: APIConfig(
                    url="http://localhost:8006/analyze_single",
                    file_param="file"
                )
            }
            
            self.logger.info(f"æˆåŠŸåŠ è½½ {len(api_configs)} ä¸ªAPIé…ç½®")
            
        except Exception as e:
            self.logger.error(f"åŠ è½½APIé…ç½®å¤±è´¥: {e}")
            # è¿”å›ç©ºé…ç½®ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿåˆ†æç»“æœ
            api_configs = {}
            
        return api_configs
    
    def _call_evidence_api(self, evidence: EvidenceItem, max_retries: int = 3) -> Optional[Dict[str, Any]]:
        """è°ƒç”¨å¯¹åº”çš„è¯æ®åˆ†æAPI"""
        if evidence.evidence_type not in self.api_configs:
            self.logger.warning(f"æœªæ‰¾åˆ° {evidence.evidence_type.value} ç±»å‹çš„APIé…ç½®")
            return None
            
        api_config = self.api_configs[evidence.evidence_type]
        
        for attempt in range(max_retries):
            try:
                self.logger.info(f"æ­£åœ¨è°ƒç”¨API: {api_config.url} (å°è¯• {attempt + 1}/{max_retries})")
                
                with open(evidence.file_path, 'rb') as f:
                    files = {api_config.file_param: f}
                    data = api_config.additional_params.copy()
                    
                    # è®¾ç½®è¯·æ±‚è¶…æ—¶
                    response = requests.post(
                        api_config.url, 
                        files=files, 
                        data=data,
                        timeout=30
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        self.logger.info(f"APIè°ƒç”¨æˆåŠŸ: {api_config.url}")
                        return result
                    else:
                        self.logger.warning(f"APIè¿”å›é”™è¯¯çŠ¶æ€ç : {response.status_code}")
                        
            except requests.exceptions.Timeout:
                self.logger.warning(f"APIè°ƒç”¨è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries})")
            except requests.exceptions.ConnectionError:
                self.logger.warning(f"APIè¿æ¥å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries})")
            except Exception as e:
                self.logger.error(f"APIè°ƒç”¨å¼‚å¸¸: {e} (å°è¯• {attempt + 1}/{max_retries})")
            
            # é‡è¯•å‰ç­‰å¾…
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                self.logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
        
        self.logger.error(f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {api_config.url}")
        return None
    
    def _save_report(self, report: Dict[str, Any]) -> str:
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        if not os.path.exists("evidence_reports"):
            os.makedirs("evidence_reports")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"evidence_reports/evidence_analysis_report_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # åŒæ—¶ç”Ÿæˆå¯è¯»æ€§æ›´å¥½çš„æ–‡æœ¬æŠ¥å‘Š
        text_filename = f"evidence_reports/evidence_analysis_report_{timestamp}.txt"
        self._save_text_report(report, text_filename)
        
        return filename
    
    def _save_text_report(self, report: Dict[str, Any], filename: str):
        """ä¿å­˜æ–‡æœ¬æ ¼å¼çš„æŠ¥å‘Š"""
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("è¯æ®åˆ†ææŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {report.get('æŠ¥å‘Šç”Ÿæˆæ—¶é—´', 'N/A')}\n\n")
            
            f.write("æ¡ˆä»¶æ¦‚è¿°:\n")
            f.write("-" * 30 + "\n")
            f.write(f"{report.get('æ¡ˆä»¶æ¦‚è¿°', 'N/A')}\n\n")
            
            f.write("æ ¸å¿ƒè¯æ®åˆ—è¡¨:\n")
            f.write("-" * 30 + "\n")
            for i, evidence in enumerate(report.get('æ ¸å¿ƒè¯æ®åˆ—è¡¨', []), 1):
                f.write(f"{i}. {evidence.get('ç±»å‹', 'N/A')}: {evidence.get('æ‘˜è¦', 'N/A')}\n")
            f.write("\n")
            
            f.write("è¾…åŠ©è¯æ®åˆ—è¡¨:\n")
            f.write("-" * 30 + "\n")
            for i, evidence in enumerate(report.get('è¾…åŠ©è¯æ®åˆ—è¡¨', []), 1):
                f.write(f"{i}. {evidence.get('ç±»å‹', 'N/A')}: {evidence.get('æ‘˜è¦', 'N/A')}\n")
            f.write("\n")
            
            f.write("LLMç»¼åˆåˆ†æ:\n")
            f.write("-" * 30 + "\n")
            f.write(f"{report.get('LLMç»¼åˆåˆ†æ', 'N/A')}\n\n")
            
            f.write("è¯æ®å®Œæ•´æ€§è¯„ä¼°:\n")
            f.write("-" * 30 + "\n")
            completeness = report.get('è¯æ®å®Œæ•´æ€§è¯„ä¼°', {})
            f.write(f"å®Œæ•´æ€§å¾—åˆ†: {completeness.get('å®Œæ•´æ€§å¾—åˆ†', 'N/A')}\n")
            f.write(f"å·²æ”¶é›†è¯æ®ç±»å‹: {completeness.get('å·²æ”¶é›†è¯æ®ç±»å‹', 'N/A')}\n")
            f.write(f"è¯†åˆ«è¯æ®ç±»å‹æ€»æ•°: {completeness.get('è¯†åˆ«è¯æ®ç±»å‹æ€»æ•°', 'N/A')}\n\n")
            
            f.write("å»ºè®®å’Œé£é™©æç¤º:\n")
            f.write("-" * 30 + "\n")
            for recommendation in report.get('å»ºè®®å’Œé£é™©æç¤º', []):
                f.write(f"â€¢ {recommendation}\n")


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºç”¨æ³•"""
    print("ğŸ›ï¸ è¯æ®åˆ†æç³»ç»Ÿå¯åŠ¨")
    print("=" * 50)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = EvidenceAnalyzer()
    
    # åˆ†æè¯æ®
    conversation_file = "d:/Code/HJY/AI lawyer full-featured demo/conversation_history_demo.json"
    
    if not os.path.exists(conversation_file):
        print(f"âŒ å¯¹è¯å†å²æ–‡ä»¶ä¸å­˜åœ¨: {conversation_file}")
        return
    
    try:
        result = analyzer.analyze_case_evidence(conversation_file)
        
        if "error" in result:
            print(f"âŒ åˆ†æå¤±è´¥: {result['error']}")
        else:
            print("\nâœ… è¯æ®åˆ†æå®Œæˆï¼")
            print(f"ğŸ“Š æ ¸å¿ƒè¯æ®æ•°é‡: {len(result.get('æ ¸å¿ƒè¯æ®åˆ—è¡¨', []))}")
            print(f"ğŸ“‹ è¾…åŠ©è¯æ®æ•°é‡: {len(result.get('è¾…åŠ©è¯æ®åˆ—è¡¨', []))}")
            print(f"ğŸ“ˆ è¯æ®å®Œæ•´æ€§: {result.get('è¯æ®å®Œæ•´æ€§è¯„ä¼°', {}).get('å®Œæ•´æ€§å¾—åˆ†', 'N/A')}")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()