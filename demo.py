#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¼”ç¤ºè„šæœ¬
ç”¨äºæµ‹è¯•AIåŠ³åŠ¨æ³•å¾‹å¸ˆè½¯ä»¶çš„åŸºæœ¬åŠŸèƒ½
"""

import os
import sys
import json
from datetime import datetime

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦å®‰è£…"""
    print("ğŸ” æ£€æŸ¥ç³»ç»Ÿä¾èµ–...")
    
    required_packages = [
        'dashscope',
        'openai', 
        'pandas',
        'requests'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package} - å·²å®‰è£…")
        except ImportError:
            print(f"âŒ {package} - æœªå®‰è£…")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nâš ï¸ ç¼ºå°‘ä»¥ä¸‹ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    
    print("\nâœ… æ‰€æœ‰ä¾èµ–åŒ…æ£€æŸ¥é€šè¿‡")
    return True

def check_files():
    """æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    print("\nğŸ“ æ£€æŸ¥é¡¹ç›®æ–‡ä»¶...")
    
    required_files = [
        'main.py',
        'lawyer_model.py',
        'free_generate_case_analysis.py', 
        'evidence_analyzer.py',
        'Lawyer_Prompt.txt'
    ]
    
    missing_files = []
    
    for file in required_files:
        if os.path.exists(file):
            print(f"âœ… {file} - å­˜åœ¨")
        else:
            print(f"âŒ {file} - ä¸å­˜åœ¨")
            missing_files.append(file)
    
    if missing_files:
        print(f"\nâš ï¸ ç¼ºå°‘ä»¥ä¸‹æ–‡ä»¶: {', '.join(missing_files)}")
        return False
    
    print("\nâœ… æ‰€æœ‰å¿…è¦æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
    return True

def create_demo_conversation():
    """åˆ›å»ºæ¼”ç¤ºå¯¹è¯æ•°æ®"""
    print("\nğŸ“ åˆ›å»ºæ¼”ç¤ºå¯¹è¯æ•°æ®...")
    
    demo_conversation = [{
        "system_prompt": "ä½œä¸ºä¸“ç²¾åŠ³åŠ¨æ³•çš„èµ„æ·±å¾‹å¸ˆï¼Œæ‚¨åœ¨å¯¹è¯ä¸­å¿…é¡»å§‹ç»ˆä»¥å…±æƒ…ã€ä¸“ä¸šçš„æ–¹å¼å¼•å¯¼ç”¨æˆ·æ¢³ç†æ¡ˆä»¶ç»†èŠ‚ã€‚",
        "conversations": [
            {
                "from": "human",
                "value": "æ‚¨å¥½ï¼Œæˆ‘æƒ³å’¨è¯¢ä¸€ä¸‹åŠ³åŠ¨äº‰è®®çš„é—®é¢˜ã€‚æˆ‘åœ¨ä¸€å®¶ç§‘æŠ€å…¬å¸å·¥ä½œäº†2å¹´ï¼Œæœ€è¿‘è¢«å…¬å¸æ— æ•…è¾é€€äº†ã€‚"
            },
            {
                "from": "gpt", 
                "value": "æ‚¨å¥½ï¼Œå¾ˆç†è§£æ‚¨ç°åœ¨çš„å›°æ‰°ã€‚è¢«æ— æ•…è¾é€€ç¡®å®è®©äººæ„Ÿåˆ°ä¸å®‰ã€‚ä¸ºäº†æ›´å¥½åœ°å¸®åŠ©æ‚¨ï¼Œæˆ‘éœ€è¦äº†è§£ä¸€äº›å…·ä½“æƒ…å†µã€‚è¯·é—®æ‚¨å’Œå…¬å¸ç­¾è®¢è¿‡ä¹¦é¢åŠ³åŠ¨åˆåŒå—ï¼Ÿ"
            },
            {
                "from": "human",
                "value": "æ˜¯çš„ï¼Œæˆ‘ä»¬ç­¾äº†3å¹´æœŸçš„åŠ³åŠ¨åˆåŒï¼Œçº¦å®šæœˆè–ª12000å…ƒã€‚ä½†æ˜¯å…¬å¸çªç„¶è¯´è¦è£å‘˜ï¼Œç»™äº†æˆ‘ä¸€ä¸ªæœˆçš„ä»£é€šçŸ¥é‡‘å°±è®©æˆ‘èµ°äº†ã€‚"
            },
            {
                "from": "gpt",
                "value": "æˆ‘æ˜ç™½äº†ã€‚å…¬å¸ç»™äº†ä»£é€šçŸ¥é‡‘ï¼Œä½†è¿™ç§åšæ³•æ˜¯å¦åˆæ³•è¿˜éœ€è¦è¿›ä¸€æ­¥åˆ†æã€‚è¯·é—®å…¬å¸æœ‰æ²¡æœ‰ç»™æ‚¨ä¹¦é¢çš„è§£é™¤åŠ³åŠ¨åˆåŒé€šçŸ¥ä¹¦ï¼Ÿä¸Šé¢å†™çš„å…·ä½“ç†ç”±æ˜¯ä»€ä¹ˆï¼Ÿ"
            },
            {
                "from": "human",
                "value": "æœ‰çš„ï¼Œé€šçŸ¥ä¹¦ä¸Šå†™çš„æ˜¯'å› ç»è¥å›°éš¾éœ€è¦è£å‘˜'ï¼Œä½†æˆ‘è§‰å¾—è¿™ä¸æ˜¯çœŸå®åŸå› ï¼Œå› ä¸ºå…¬å¸è¿˜åœ¨æ‹›æ–°äººã€‚"
            },
            {
                "from": "gpt",
                "value": "è¿™ä¸ªæƒ…å†µç¡®å®å€¼å¾—å…³æ³¨ã€‚å¦‚æœå…¬å¸ä¸€è¾¹è¯´è£å‘˜ä¸€è¾¹æ‹›æ–°äººï¼Œå¯èƒ½å­˜åœ¨è¿æ³•è§£é™¤çš„æƒ…å†µã€‚è¯·é—®æ‚¨åœ¨å…¬å¸çš„å…·ä½“å²—ä½æ˜¯ä»€ä¹ˆï¼Ÿå·¥ä½œè¡¨ç°å¦‚ä½•ï¼Ÿæœ‰æ²¡æœ‰è¿åå…¬å¸è§„ç« åˆ¶åº¦çš„æƒ…å†µï¼Ÿ"
            },
            {
                "from": "human",
                "value": "æˆ‘æ˜¯è½¯ä»¶å¼€å‘å·¥ç¨‹å¸ˆï¼Œå·¥ä½œè¡¨ç°ä¸€ç›´å¾ˆå¥½ï¼Œä»æ¥æ²¡æœ‰è¿åè¿‡å…¬å¸åˆ¶åº¦ã€‚è€Œä¸”æˆ‘å‘ç°å…¬å¸åœ¨æˆ‘è¢«è¾é€€åä¸€å‘¨å°±å‘å¸ƒäº†åŒæ ·å²—ä½çš„æ‹›è˜ä¿¡æ¯ã€‚"
            },
            {
                "from": "gpt",
                "value": "æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œè¿™ç§æƒ…å†µå¾ˆå¯èƒ½æ„æˆè¿æ³•è§£é™¤åŠ³åŠ¨åˆåŒã€‚å…¬å¸ä»¥ç»è¥å›°éš¾ä¸ºç”±è£å‘˜ï¼Œä½†åŒæ—¶æ‹›è˜åŒå²—ä½äººå‘˜ï¼Œè¿™åœ¨æ³•å¾‹ä¸Šæ˜¯ç«™ä¸ä½è„šçš„ã€‚æ‚¨ç°åœ¨æœ€éœ€è¦åšçš„æ˜¯æ”¶é›†ç›¸å…³è¯æ®ï¼Œæ¯”å¦‚æ‹›è˜ä¿¡æ¯çš„æˆªå›¾ã€æ‚¨çš„å·¥ä½œè¡¨ç°è¯æ˜ç­‰ã€‚å…³äºå…·ä½“çš„èµ”å¿æ ‡å‡†å’Œç»´æƒæ–¹å¼ï¼Œæˆ‘ä»¬å·²ç»æ”¶é›†äº†è¶³å¤Ÿçš„åŸºç¡€ä¿¡æ¯ã€‚"
            }
        ]
    }]
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs("conversation_datasets", exist_ok=True)
    
    # ä¿å­˜æ¼”ç¤ºå¯¹è¯
    demo_file = "conversation_datasets/demo_conversation.json"
    with open(demo_file, 'w', encoding='utf-8') as f:
        json.dump(demo_conversation, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æ¼”ç¤ºå¯¹è¯æ•°æ®å·²åˆ›å»º: {demo_file}")
    return demo_file

def test_case_analysis(conversation_file):
    """æµ‹è¯•æ¡ˆä¾‹åˆ†æåŠŸèƒ½"""
    print("\nâš–ï¸ æµ‹è¯•æ¡ˆä¾‹åˆ†æåŠŸèƒ½...")
    
    try:
        from free_generate_case_analysis import CaseAnalysisGenerator
        
        # åˆ›å»ºåˆ†æå™¨ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼‰
        analyzer = CaseAnalysisGenerator()
        
        # æ¨¡æ‹Ÿåˆ†æç»“æœï¼ˆé¿å…å®é™…APIè°ƒç”¨ï¼‰
        mock_result = """
ã€æ¡ˆæƒ…åˆ†æã€‘
æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œæ‚¨ä¸å…¬å¸ç­¾è®¢äº†3å¹´æœŸåŠ³åŠ¨åˆåŒï¼Œçº¦å®šæœˆè–ª12000å…ƒï¼Œåœ¨èŒæœŸé—´å·¥ä½œè¡¨ç°è‰¯å¥½ï¼Œæ— è¿çºªè¡Œä¸ºã€‚å…¬å¸ä»¥"ç»è¥å›°éš¾éœ€è¦è£å‘˜"ä¸ºç”±è§£é™¤åŠ³åŠ¨åˆåŒï¼Œä½†åŒæ—¶å‘å¸ƒåŒå²—ä½æ‹›è˜ä¿¡æ¯ï¼Œè¿™ç§è¡Œä¸ºåœ¨æ³•å¾‹ä¸Šå­˜åœ¨æ˜æ˜¾çŸ›ç›¾ï¼Œå¾ˆå¯èƒ½æ„æˆè¿æ³•è§£é™¤åŠ³åŠ¨åˆåŒã€‚

ã€å½“å‰åº”å¯¹æ–¹æ¡ˆã€‘
å»ºè®®æ‚¨ç«‹å³æ”¶é›†ä»¥ä¸‹è¯æ®ï¼š1ï¼‰å…¬å¸å‘å¸ƒçš„åŒå²—ä½æ‹›è˜ä¿¡æ¯æˆªå›¾ï¼›2ï¼‰æ‚¨çš„å·¥ä½œè¡¨ç°è¯æ˜ææ–™ï¼›3ï¼‰åŠ³åŠ¨åˆåŒåŸä»¶ï¼›4ï¼‰è§£é™¤åŠ³åŠ¨åˆåŒé€šçŸ¥ä¹¦ã€‚åŒæ—¶ï¼Œæ‚¨å¯ä»¥å‘åŠ³åŠ¨ç›‘å¯Ÿéƒ¨é—¨ä¸¾æŠ¥æˆ–ç”³è¯·åŠ³åŠ¨ä»²è£ï¼Œè¦æ±‚å…¬å¸æ‰¿æ‹…è¿æ³•è§£é™¤çš„æ³•å¾‹è´£ä»»ã€‚

ã€ç»´æƒä¸èµ”å¿æ–¹æ¡ˆã€‘
æ ¹æ®ã€ŠåŠ³åŠ¨åˆåŒæ³•ã€‹ç¬¬87æ¡è§„å®šï¼Œç”¨äººå•ä½è¿æ³•è§£é™¤åŠ³åŠ¨åˆåŒçš„ï¼Œåº”å½“æŒ‰ç…§ç»æµè¡¥å¿æ ‡å‡†çš„äºŒå€å‘åŠ³åŠ¨è€…æ”¯ä»˜èµ”å¿é‡‘ã€‚ä»¥æ‚¨çš„æƒ…å†µè®¡ç®—ï¼Œåº”è·å¾—èµ”å¿é‡‘ä¸ºï¼š12000å…ƒÃ—2å¹´Ã—2å€=48000å…ƒã€‚æ­¤å¤–ï¼Œæ‚¨è¿˜å¯ä»¥è¦æ±‚å…¬å¸æ”¯ä»˜ä»£é€šçŸ¥é‡‘ã€æœªä¼‘å¹´å‡å·¥èµ„ç­‰å…¶ä»–åˆæ³•æƒç›Šã€‚
"""
        
        print("âœ… æ¡ˆä¾‹åˆ†æåŠŸèƒ½æµ‹è¯•é€šè¿‡")
        print("ğŸ“‹ åˆ†æç»“æœç¤ºä¾‹:")
        print("-" * 50)
        print(mock_result[:200] + "...")
        print("-" * 50)
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¡ˆä¾‹åˆ†æåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_evidence_analysis():
    """æµ‹è¯•è¯æ®åˆ†æåŠŸèƒ½"""
    print("\nğŸ”¬ æµ‹è¯•è¯æ®åˆ†æåŠŸèƒ½...")
    
    try:
        from evidence_analyzer import EvidenceAnalyzer, EvidenceType
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer = EvidenceAnalyzer()
        
        print("âœ… è¯æ®åˆ†ææ¨¡å—åŠ è½½æˆåŠŸ")
        print("ğŸ“‹ æ”¯æŒçš„è¯æ®ç±»å‹:")
        
        for evidence_type in EvidenceType:
            print(f"  â€¢ {evidence_type.value}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¯æ®åˆ†æåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def run_demo():
    """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
    print("ğŸš€ AIåŠ³åŠ¨æ³•å¾‹å¸ˆè½¯ä»¶æ¼”ç¤º")
    print("=" * 60)
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return False
    
    # æ£€æŸ¥æ–‡ä»¶
    if not check_files():
        return False
    
    # åˆ›å»ºæ¼”ç¤ºæ•°æ®
    demo_file = create_demo_conversation()
    
    # æµ‹è¯•å„ä¸ªæ¨¡å—
    case_analysis_ok = test_case_analysis(demo_file)
    evidence_analysis_ok = test_evidence_analysis()
    
    print("\nğŸ“Š æ¼”ç¤ºç»“æœæ€»ç»“:")
    print("=" * 40)
    print(f"ä¾èµ–æ£€æŸ¥: âœ…")
    print(f"æ–‡ä»¶æ£€æŸ¥: âœ…")
    print(f"æ¡ˆä¾‹åˆ†æ: {'âœ…' if case_analysis_ok else 'âŒ'}")
    print(f"è¯æ®åˆ†æ: {'âœ…' if evidence_analysis_ok else 'âŒ'}")
    
    if case_analysis_ok and evidence_analysis_ok:
        print("\nğŸ‰ æ‰€æœ‰åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ’¡ ç°åœ¨æ‚¨å¯ä»¥è¿è¡Œä¸»ç¨‹åº:")
        print("   python main.py")
        return True
    else:
        print("\nâš ï¸ éƒ¨åˆ†åŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return False

if __name__ == "__main__":
    try:
        success = run_demo()
        if not success:
            sys.exit(1)
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æ¼”ç¤ºå·²å–æ¶ˆ")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)